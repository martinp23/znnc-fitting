{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mamba create -n binding -c conda-forge python jupyter ipython uncertainties lmfit scipy numpy emcee numba corner matplotlib numdifftools\n",
    "\n",
    "\n",
    "# Import necessary modules. \n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from numba import jit # this package is very valuable for increasing the efficiency of the script\n",
    "#from optimparallel import minimize_parallel  # not required but can be useful if you want to do parallel LBGFS\n",
    "from IPython.display import display, Markdown # lets us print tables of values tables using standard iPython\n",
    "from uncertainties import ufloat,umath\n",
    "import lmfit,emcee,corner\n",
    "from multiprocessing import Pool,cpu_count\n",
    "import os\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42 \n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = \"Arial\"\n",
    "plt.rcParams['font.size'] = 8\n",
    "\n",
    "# Set everything up - all functions for fitting\n",
    "# \n",
    "# #https://github.com/numba/numba/issues/1269#issuecomment-702665837\n",
    "# This solution enables us to apply the overloaded np.prod function along a single axis, see link above\n",
    "@jit(nopython=True)\n",
    "def apply_along_axis_0(func1d, arr):\n",
    "    \"\"\"Like calling func1d(arr, axis=0)\"\"\"\n",
    "    if arr.size == 0:\n",
    "        raise RuntimeError(\"Must have arr.size > 0\")\n",
    "    ndim = arr.ndim\n",
    "    if ndim == 0:\n",
    "        raise RuntimeError(\"Must have ndim > 0\")\n",
    "    elif 1 == ndim:\n",
    "        return func1d(arr)\n",
    "    else:\n",
    "        result_shape = arr.shape[1:]\n",
    "        out = np.empty(result_shape, arr.dtype)\n",
    "        _apply_along_axis_0(func1d, arr, out)\n",
    "        return out\n",
    "\n",
    "# This solution enables us to apply the overloaded np.prod function along a single axis, see link above\n",
    "@jit\n",
    "def _apply_along_axis_0(func1d, arr, out):\n",
    "    \"\"\"Like calling func1d(arr, axis=0, out=out). Require arr to be 2d or bigger.\"\"\"\n",
    "    ndim = arr.ndim\n",
    "    if ndim < 2:\n",
    "        raise RuntimeError(\"_apply_along_axis_0 requires 2d array or bigger\")\n",
    "    elif ndim == 2:  # 2-dimensional case\n",
    "        for i in range(len(out)):\n",
    "            out[i] = func1d(arr[:, i])\n",
    "    else:  # higher dimensional case\n",
    "        for i, out_slice in enumerate(out):\n",
    "            _apply_along_axis_0(func1d, arr[:, i], out_slice)\n",
    "\n",
    "# This function solves the equilibrium concentration problem based on equilibrium constants, adapted\n",
    "# from Maeder and co workers: https://doi.org/10.1016/S0922-3487(07)80006-2\n",
    "@jit(nopython=True)\n",
    "def getConcs(eqMat,initComponentConc,logK):\n",
    "    # now we give a vector containing the (log) equilibrium constants. Be careful\n",
    "    # with sign because these constants are for formation of the complexes\n",
    "    # above from the \"pure components\". \n",
    "    K = 10.0**logK\n",
    "\n",
    "    # make an initial guess. This doesn't need to be good - it should just\n",
    "    # be nearly-equally bad for all parameters\n",
    "    initguess = np.array([0,0,0]) + np.mean(initComponentConc)\n",
    "\n",
    "    # solve the equilibrium problem above using the Newton Raphson method\n",
    "    comp,spec = DoNR(eqMat,K,initComponentConc,initguess)\n",
    "    return spec\n",
    "\n",
    "\n",
    "# This function implements the Newton Raphson method for solving the equilibrium problem\n",
    "# following: https://doi.org/10.1016/S0922-3487(07)80006-2\n",
    "@jit(nopython=True)\n",
    "def DoNR(eqMat,K,initComponentConc,guessCompConc):\n",
    "    nspecies = len(K)\n",
    "    ncomp = len(initComponentConc)\n",
    "    \n",
    "    initComponentConc[initComponentConc<=0] = 1e-20 # avoids numerical errors. Changed to <=0 rather than == 0 because sometimes small negative errors appear which makes\n",
    "                                                    # the optimisation impossible\n",
    "    for iter in range(0,500):\n",
    "\n",
    "        conc = guessCompConc\n",
    "\n",
    "        specmat = conc.repeat(nspecies).reshape((-1, nspecies))\n",
    "\n",
    "        eq3pt47 = apply_along_axis_0(np.prod,specmat**eqMat)\n",
    "        speciesConc = K * eq3pt47  # eq 3.48\n",
    "\n",
    "        compTotCalc = eqMat @ speciesConc\n",
    "        deltaComp = initComponentConc - compTotCalc\n",
    "\n",
    "        if np.all(np.abs(deltaComp) < 1e-15):\n",
    "            return compTotCalc,speciesConc\n",
    "\n",
    "        J = np.zeros((ncomp,ncomp))\n",
    "\n",
    "        # calculate Jacobian\n",
    "        for ii in range(0,ncomp):\n",
    "            for jj in range(0,ncomp):\n",
    "                J[ii,jj] = np.sum(eqMat[ii,:]*eqMat[jj,:]*speciesConc)\n",
    "                J[jj,ii] = J[ii,jj]\n",
    "\n",
    "        deltaConc = np.linalg.lstsq(J, deltaComp)[0].T * conc # , rcond=None\n",
    "        conc += deltaConc\n",
    "\n",
    "        while np.any(conc <= 0):\n",
    "            deltaConc = deltaConc/2\n",
    "            conc -= deltaConc\n",
    "            if np.all(np.abs(deltaConc)<1e-15):\n",
    "                break\n",
    "\n",
    "    # Only reached if the optimisation does not complete within the available steps (500)\n",
    "    print(\"Failed to converge in equilibrium solver doNR\")\n",
    "    print('deltaComp: ',deltaComp)\n",
    "    print('initComponentConc: ',initComponentConc)\n",
    "    print('K: ',K)\n",
    "    # return something here which indicates that the result is wrong\n",
    "    return 0*compTotCalc,0*speciesConc\n",
    "\n",
    "\n",
    "def fitfun(params,compConcs,eqMat,specConcs,ret='residual'):\n",
    "    if type(params) == lmfit.parameter.Parameters:\n",
    "        parvals = params.valuesdict().values()\n",
    "    else: \n",
    "        parvals = params\n",
    "\n",
    "    specCalc = []\n",
    "    for row in compConcs:\n",
    "        yEq = getConcs(eqMat,row,np.array([0,0,0,*parvals],dtype=np.float64))\n",
    "        specCalc.append(yEq[3:])\n",
    "    specCalc = np.array(specCalc)\n",
    "    #return(specConcs-spec)\n",
    "    sigma = 1#specConcs*0.05 + np.min(specConcs)/2\n",
    "    if ret == 'residual':\n",
    "        return((specConcs-specCalc)/(sigma))\n",
    "    elif ret == 'concs':\n",
    "        return specCalc\n",
    "    else:\n",
    "        print(\"Invalid return argument. Options: 'residual' [default] or 'concs'\")\n",
    "        return -1\n",
    "\n",
    "\n",
    "def logprior(par):\n",
    "    if par[2]<par[1] or par[1]<par[0]:\n",
    "        return -np.inf\n",
    "    if  par[2]>30 or par[2]<8:\n",
    "        return -np.inf\n",
    "    if par[1]>20 or par[1]<3:\n",
    "        return -np.inf\n",
    "    if par[0]>12 or par[0]<3:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def fitfun_mc(params,compConcs,eqMat,specConcs):\n",
    "    if type(params) == lmfit.parameter.Parameters:\n",
    "        parvals = list(params.valuesdict().values())\n",
    "    else: \n",
    "        parvals = params\n",
    "    \n",
    "    \n",
    "    params = parvals[:-1]#.valuesdict().values()\n",
    "    lnsigma = parvals[-1]\n",
    "    params = [*params][0:len(eqMat)]\n",
    "    specCalc = []\n",
    "\n",
    "\n",
    "    # if a param is getting silly, reject by checking against the priors\n",
    "    lp = logprior(params)\n",
    "    if np.isinf(lp):\n",
    "        return lp\n",
    "\n",
    "    for row in compConcs:\n",
    "        try:\n",
    "            yEq = getConcs(eqMat,row,np.array([0,0,0,*params],dtype=np.float64))\n",
    "        except np.linalg.LinAlgError:\n",
    "            return -np.inf\n",
    "        # if the maths doesn't work then the solution is deemed impossible\n",
    "        specCalc.append(yEq[3:])\n",
    "    specCalc = np.array(specCalc)\n",
    "\n",
    "    return (-0.5*np.sum(\n",
    "                        ((specConcs-specCalc) / np.exp(lnsigma))**2 \n",
    "                        + np.log(2*np.pi) + 2*lnsigma))\n",
    "\n",
    "\n",
    "def diffEvolFunc(x,specConcs,compConcs):\n",
    "    res = fitfun(compConcs,x[0],x[0]*x[1],x[0]*x[1]*x[2])\n",
    "\n",
    "    return sum((specConcs.flatten() - res)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic least_squares fitting and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# defines the speciation of the system\n",
    "                    #  Nc, Py, DABCO, NcPy NcDABCO Nc2DABCO\n",
    "eqMat =   np.array([[1, 0, 0, 1,   1,      2],  # Nc\n",
    "                    [0, 1, 0, 1,   0,      0],     # Py\n",
    "                    [0, 0, 1, 0,   1,      1]],dtype=np.float64)     # DABCO\n",
    "\n",
    "# initial assignment of parameters for least_squares solution\n",
    "params = lmfit.Parameters()\n",
    "params['logB1'] = lmfit.Parameter('logB1',8,min=3,max=10,vary=True)\n",
    "params['logB2'] = lmfit.Parameter('logB2',9,min=3,max=14,vary=True)\n",
    "params['logB3'] = lmfit.Parameter('logB3',18,min=5,max=30,vary=True)\n",
    "\n",
    "# load experimental NMR data\n",
    "data = (np.loadtxt('titration-data.csv',skiprows=1,delimiter=','))\n",
    "\n",
    "compConcs = data[:,0:3]\n",
    "specConcs = data[:,3:]\n",
    "\n",
    "\n",
    "# detrend data; note that total concentration of Nc seems to rise over time. \n",
    "# so we set the constraint that the sum of the concentrations must be 1.99e-4 \n",
    "\n",
    "totalNc = specConcs[:,0]+specConcs[:,1]+2*specConcs[:,2]\n",
    "scaleFac = 1.99e-4/totalNc\n",
    "specConcs[:,0] = specConcs[:,0] * scaleFac\n",
    "specConcs[:,1] = specConcs[:,1] * scaleFac\n",
    "specConcs[:,2] = specConcs[:,2] * scaleFac\n",
    "\n",
    "# least_squares fit\n",
    "mini = lmfit.Minimizer(fitfun,params,fcn_args=(compConcs,eqMat,specConcs))\n",
    "mm = mini.minimize(method='least_squares',verbose=1)\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFitResidPlot(logKs,compConcs,eqMat,specConcs,figname=None):\n",
    "    specCalc=fitfun(logKs,compConcs,eqMat,specConcs,ret='concs')\n",
    "    plt.gcf().clear()\n",
    "    sf=1 # fig scale factor from single col\n",
    "    ms=15 #marker size\n",
    "\n",
    "    plt.figure(figsize=(sf*85/22.5,sf*70/22.5))\n",
    "    # plt.scatter(compConcs[:,2],(calcSpec[:,3]-specConcs[:,0])/specConcs[:,0])\n",
    "    # plt.scatter(compConcs[:,2],(calcSpec[:,4]-specConcs[:,1])/specConcs[:,1])\n",
    "    # plt.scatter(compConcs[:,2],(calcSpec[:,5]-specConcs[:,2])/specConcs[:,2])\n",
    "\n",
    "    colours = ['r','k','b']\n",
    "    points = ['^','s','o']\n",
    "    plt.scatter(10e3*compConcs[:,2],10e6*(specConcs[:,0]-specCalc[:,0]),marker=points[0],c=colours[0],label=\"ZnNc${\\cdot}$pyridine\",s=ms)\n",
    "    plt.scatter(10e3*compConcs[:,2],10e6*(specConcs[:,1]-specCalc[:,1]),marker=points[1],c=colours[1],label=\"ZnNc${\\cdot}$DABCO\",s=ms)\n",
    "    plt.scatter(10e3*compConcs[:,2],10e6*(specConcs[:,2]-specCalc[:,2]),marker=points[2],c=colours[2],label=\"ZnNc$_{2}{\\cdot}$DABCO\",s=ms)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('[DABCO]$_{tot}$ (mM)')\n",
    "    plt.ylabel(\"[species]$_{expt}$ - [species]$_{calc}$ (Î¼M)\")\n",
    "    if figname is not None:\n",
    "        plt.savefig(figname+'-residuals.pdf', bbox_inches=\"tight\")\n",
    "        plt.savefig(figname+'-residuals.png',dpi=1200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # calculate more continuous range of concentrations\n",
    "\n",
    "    concrange = np.arange(0,np.max(compConcs[:,2])+np.max(compConcs[:,2])/50,np.max(compConcs[:,2])/102)\n",
    "    staticConc = compConcs[0,0]\n",
    "\n",
    "    compFull = np.ones([len(concrange),3])*staticConc\n",
    "    compFull[:,2] = concrange\n",
    "    calcSpecFull = calculateSpeciation(eqMat,compFull,logKs)\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(sf*85/22.5,sf*70/22.5))\n",
    "    #plt.subplot(212)\n",
    "    plt.scatter(10e3*compConcs[:,2],10e3*specConcs[:,0],marker=points[0],c=colours[0],label=\"ZnNc${\\cdot}$pyridine\",s=ms)\n",
    "    plt.scatter(10e3*compConcs[:,2],10e3*specConcs[:,1],marker=points[1],c=colours[1],label=\"ZnNc${\\cdot}$DABCO\",s=ms)\n",
    "    plt.scatter(10e3*compConcs[:,2],10e3*specConcs[:,2],marker=points[2],c=colours[2],label=\"ZnNc$_{2}{\\cdot}$DABCO\",s=ms)\n",
    "\n",
    "    plt.plot(10e3*compFull[:,2],10e3*calcSpecFull[:,3],c=colours[0])\n",
    "    plt.plot(10e3*compFull[:,2],10e3*calcSpecFull[:,4],c=colours[1])\n",
    "    plt.plot(10e3*compFull[:,2],10e3*calcSpecFull[:,5],c=colours[2])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('[DABCO]$_{tot}$ (mM)')\n",
    "    plt.ylabel('[species] (mM)')\n",
    "    if figname is not None:\n",
    "        plt.savefig(figname+'.pdf', bbox_inches=\"tight\")\n",
    "        plt.savefig(figname+'.png',dpi=1200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def calculateSpeciation(eqMat,compConcs,logKs):\n",
    "    calcSpec = []\n",
    "    for row in compConcs:\n",
    "        test = getConcs(eqMat,row,np.array([0,0,0,*logKs]))\n",
    "        calcSpec.append(test)\n",
    "    calcSpec = np.array(calcSpec)\n",
    "    return calcSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "makeFitResidPlot([7.46,9.35,17.31],compConcs,eqMat,specConcs,figname='lsq-result')\n",
    "Kpy = 6\n",
    "makeFitResidPlot([Kpy, Kpy+1.98, 2*(Kpy+1.98)-1.45],compConcs,eqMat,specConcs,figname='Kpy-6')\n",
    "\n",
    "makeFitResidPlot([8.57,10.55,19.65],compConcs,eqMat,specConcs,figname='mle-result')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResidualForKPy(Kpy):\n",
    "    #specCalc=fitfun([Kpy, Kpy+1.98, 2*Kpy+2.51],compConcs,eqMat,specConcs,ret='concs')\n",
    "    specCalc=fitfun([Kpy, Kpy+1.98, 2*(Kpy+1.98)-1.45],compConcs,eqMat,specConcs,ret='concs')\n",
    "    return(np.sum((specConcs[:,:3]-specCalc[:,:3])**2))\n",
    "\n",
    "\n",
    "\n",
    "Kpy = np.arange(4,10,0.01)\n",
    "plt.subplots(1,2,figsize=(125/25.4,70/25.4))\n",
    "plt.subplot(121)\n",
    "plt.plot(Kpy,[getResidualForKPy(x) for x in Kpy])\n",
    "plt.xlabel(r\"$\\log{\\beta_1}$\")\n",
    "plt.ylabel('Sum-of-squares error')\n",
    "plt.subplot(122)\n",
    "Kpy = np.arange(6.75,8,0.005)\n",
    "plt.plot(Kpy,[getResidualForKPy(x) for x in Kpy])\n",
    "plt.xlabel(r\"$\\log{\\beta_1}$\")\n",
    "plt.ylabel('Sum-of-squares error')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sse-vs-b1.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "\n",
    "nwalkers = 50\n",
    "\n",
    "variance = .01\n",
    "\n",
    "params = list(mm.params.valuesdict().values())\n",
    "params.append(-13)\n",
    "ndim = len(params)\n",
    "# prior normal\n",
    "p = params + variance * np.random.randn(nwalkers,ndim)\n",
    "# prior is lognormal\n",
    "p =  np.random.lognormal(np.log(params[:3]), variance,size=(nwalkers,3))\n",
    "\n",
    "\n",
    "\n",
    "# a better prior recognises that:\n",
    "# 1. we know that all logB_1 are non-negative\n",
    "# 2. we know that logB_2 > logB_1\n",
    "# 3. we know that logB_3 > logB_2\n",
    "\n",
    "# two obvious options:\n",
    "# a. create a distribution of logB1, then generate logB2 and logB3 by multiplication by a log-normal distributed scalar (probably mu=0, sigma = 0.5)\n",
    "# b. create log-normal distribution on each parameter and discard all sets which fail the constraints\n",
    "# I think the latter is cleaner.\n",
    "\n",
    "\n",
    "# first make too many walkers:\n",
    "p =  np.random.lognormal(np.log(params[:3]), variance,size=(10*nwalkers,3))\n",
    "p=np.append(p, params[3] + variance * np.random.randn(10*nwalkers,1),axis=1)\n",
    "\n",
    "\n",
    "print(p)\n",
    "p = [pp for pp in p if  not np.isinf(logprior(pp))]\n",
    "# p = [pp for pp in p if  pp[1]>pp[0]]\n",
    "# # enforce bounds\n",
    "# p = [pp for pp in p if pp[2]<30 and pp[2]>5]\n",
    "# p = [pp for pp in p if pp[1]<20 and pp[1]>3]\n",
    "# p = [pp for pp in p if pp[0]<20 and pp[0]>3]\n",
    "\n",
    "p = p[:nwalkers]\n",
    "\n",
    "# check parameterspace\n",
    "\n",
    "pp = np.array(p)\n",
    "\n",
    "bin1d = 40\n",
    "\n",
    "fig,ax=plt.subplots(3,3,figsize=(10,8))\n",
    "#histograms\n",
    "\n",
    "plt.subplot(331)\n",
    "plt.hist(pp[:,0],bins=bin1d)\n",
    "\n",
    "plt.subplot(335)\n",
    "plt.hist(pp[:,1],bins=bin1d)\n",
    "\n",
    "plt.subplot(339)\n",
    "plt.hist(pp[:,2],bins=bin1d)\n",
    "plt.xlabel('logB3')\n",
    "\n",
    "plt.subplot(334)\n",
    "# plt.scatter(pp[:,0],pp[:,1])\n",
    "\n",
    "plt.hist2d(pp[:,0],pp[:,1],bins=(40,40),cmap=plt.cm.Greys)\n",
    "plt.xlabel('logB1')\n",
    "plt.ylabel('logB2')\n",
    "\n",
    "plt.subplot(337)\n",
    "plt.hist2d(pp[:,0],pp[:,2],bins=(40,40),cmap=plt.cm.Greys)\n",
    "plt.xlabel('logB1')\n",
    "plt.ylabel('logB3')\n",
    "\n",
    "plt.subplot(338)\n",
    "plt.hist2d(pp[:,1],pp[:,2],bins=(40,40),cmap=plt.cm.Greys)\n",
    "plt.xlabel('logB2')\n",
    "plt.ylabel('logB3')\n",
    "for aa in fig.get_axes():\n",
    "    x0,x1 = aa.get_xlim()\n",
    "    y0,y1 = aa.get_ylim()\n",
    "    aa.set_aspect((x1-x0)/(y1-y0))\n",
    "\n",
    "# hide unwanted axes\n",
    "unwanted = [332,333,336]\n",
    "for aa in unwanted:\n",
    "    ax=plt.subplot(aa)\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "corner.corner(np.array(pp))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('emcee-40k.pkl','rb') as f:\n",
    "    samplerWide = pkl.load(f)\n",
    "\n",
    "# run model\n",
    "nstep = 20000\n",
    "# multiprocessing does not work on Windows in my hands. Works on WSL though.\n",
    "# with Pool(processes=8) as pool:\n",
    "\n",
    "\n",
    "# pool=None\n",
    "# samplerWide = emcee.EnsembleSampler(nwalkers,ndim,fitfun_mc,pool=pool,args=(compConcs,eqMat,specConcs))\n",
    "# r=samplerWide.run_mcmc(p,nstep,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=8) as pool:\n",
    "    samplerWide.pool=pool\n",
    "    r=samplerWide.run_mcmc(p,20000,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open('emcee-40k.pkl','wb') as f:\n",
    "#     pkl.dump(samplerWide,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = samplerWide.get_autocorr_time()\n",
    "print(tau)\n",
    "flat_samples = samplerWide.get_chain(discard=int(np.round(np.max(tau)*100)), thin=100, flat=True)\n",
    "\n",
    "print(params)\n",
    "plt.figure()\n",
    "corner.corner(flat_samples,bins=50,show_titles=True,group='posterior',divergences=True,truths=[7.46,9.35,17.31,0],labels=[r\"$\\log{\\beta_1}$\",r\"$\\log{\\beta_2}$\",r\"$\\log{\\beta_3}$\",'lnsigma'],quantiles=[0.16,0.5,0.84])#,range=(0.95,.95,.95,.95))#,truths=params)\n",
    "plt.savefig('corner-mcmc.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat optimal result but with sigma\n",
    "sig = specConcs.flatten()/40 + min(specConcs.flatten())/5  # i.e. every data point has 2.5% error *plus* half of the lowest concentration (i.e. we are very unsure about low concentrations)\n",
    "res,ssq,_=fitTrial(fitfun,compConcs,specConcs,sig=sig,initGuess=[7,9,17])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0GuessList = [4,6,8,10]\n",
    "p1GuessList = [5,7,9,11,13,15]\n",
    "p2GuessList = [7,9,10,12,14,16,18,20]\n",
    "\n",
    "guess = []\n",
    "res = []\n",
    "ssq = []\n",
    "\n",
    "for ii in p0GuessList:\n",
    "    for ij in p1GuessList:\n",
    "        for ik in p2GuessList:\n",
    "            try:\n",
    "                r,s,_=fitTrial(fitfun,compConcs,specConcs,initGuess=[ii,ij,ik])\n",
    "                guess.append([ii,ij,ik])\n",
    "                res.append(r)\n",
    "                ssq.append(s)\n",
    "                print(\"Initial guess: [{},{},{}]\\n\".format(ii,ij,ik))\n",
    "            except:\n",
    "                print(\"\\nFAILED Initial guess: [{},{},{}]\\n\".format(ii,ij,ik))\n",
    "                guess.append([ii,ij,ik])\n",
    "                res.append(0)\n",
    "                ssq.append(1)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ij,ii in enumerate(res):\n",
    "    if ii is not 0:\n",
    "        print(ii,ssq[ij])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(1,8),(1,2.2),(1,2.2)]\n",
    "lc=sp.optimize.LinearConstraint([[0,0,1]],1,25)\n",
    "res = sp.optimize.differential_evolution(diffEvolFunc,bounds,args=(specConcs,compConcs),disp=True,x0=[7.4,1.27,1.84],constraints=lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)\n",
    "\n",
    "x= res.x\n",
    "print(x[0],x[0]*x[1],x[0]*x[1]*x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciscratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
